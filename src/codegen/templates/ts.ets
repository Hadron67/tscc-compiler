/*
    generated by jscc, an LALR(1) parser generator made by hadroncfy.
    template for typescript, written by hadroncfy, aussi.
*/
<% for(let h of input.file.header){ %>
<%- h.val %>
<% }
let prefix = input.file.prefix;
let tab = getOpt('tab', '    ');
let ists = input.output === 'typescript';
function ts(s: string, s2?: string){
    return ists ? s : (s2 || '');
}
function n(t: JNode, def: string = ''){
    return t === null ? def : t.val;
}
function getOpt(n: string, def: string){
    let t = input.file.opt[n];
    return t === undefined ? def : t.val.val;
}
function echo(s: string | number){
    output.write(s);
}
function echoLine(s: string | number){
    output.writeln(s);
}
function leftAlign(s: string, al: number): string{
    function repeat(s: string, t: number){
        let ret = '';
        while(t --> 0) ret += s;
        return ret;
    }
    return (s.length < al ? repeat(' ', al - s.length) : '') + s;
}
function printTable<T>(tname: string, t: T[], align: number, lc: number, mapper: (d: T) => string){
    let count = 1; %>
var <%- prefix + tname %> = [ 

    <% echo(tab); %>
    <% for(let i of t){
        echo(leftAlign(mapper(i), align));
        echo(',');
        count++ >= lc && (count = 1, echo(input.endl + tab));
    } %>
]; 
<% } 
function printState(state: State<LexAction[]>){ 
    function arcToString(arc: Arc<LexAction[]>): string{
        let ret: string[] = [];
        arc.chars.forEach((from, to) => {
            if(from === to){
                ret.push(`c === ${from}`);
            }
            else if(from === 0 && to !== Inf.oo){
                ret.push(`c <= ${to}`);
            }
            else if(from !== 0 && to === Inf.oo){
                ret.push(`c >= ${from}`);
            }
            else if(from !== 0 && to !== Inf.oo){
                ret.push(`(c >= ${from} && c <= ${to})`);
            }
            else {
                // this merely happens
                ret.push('true');
            }
        });
        return ret.join(' || ');
    }

    let first = true; %>
        case <%- state.index %>:
            ret.hasArc = <%- state.arcs.length > 0 ? 'true' : 'false' %>;
            ret.isEnd = <%- state.endAction === null ? 'false' : 'true' %>;
    <% if(state.arcs.length === 0){ %>
            ret.state = -1;
    <% } else if(state.hasDefinate()){ %>
            ret.state = <%- state.arcs[0].to.index %>;
    <% } else {
        for(let arc of state.arcs){ %>
            <%- first ? (first = false, '') : 'else ' %>if(<%- arcToString(arc) %>){
                ret.state = <%- arc.to.index %>;
            }
        <% } %>
            else {
                ret.state = -1;
            } 
    <% } %>
            break;
<% } 
function printDFA(dfa: DFA<LexAction[]>, n: number){ %>
function moveDFA<%- n %>(c<%- ts(": number") %>, ret<%- ts(": { state: number, hasArc: boolean, isEnd: boolean }") %>){
    switch(ret.state){
    <% for(let state of dfa.states){
        printState(state);
    } %>
        default:
            ret.state = -1;
            ret.hasArc = false;
    }
}
<% }
function printLexTokens(dfa: DFA<LexAction[]>, n: number){
    function getAction(act: LexAction[]): number{
        for(let a of act){
            if(a.token !== -1){
                return a.token;
            }
        }
        return -1;
    }
    printTable<State<LexAction[]>>('lexTokens' + n, dfa.states, 6, 10, (state) => {
        return state.endAction ? getAction(state.endAction.data).toString() : '-1';
    });
} %>
<% let dfas = input.file.lexDFA; %>
/*
    find the next state to go in the dfa
*/
<% for(let i = 0, _a = dfas; i < _a.length; i++){
    printDFA(_a[i], i);
} %>

/*
    all the lexer data goes here.
*/
var <%- prefix %>lexers = [
<% for(let i = 0;i < dfas.length;i++){ %>
    moveDFA<%- i %>,
<% } %>
];

/*
    tokens that a lexical dfa state can return
*/
<% for(let i = 0, _a = dfas; i < _a.length; i++){
    printLexTokens(_a[i], i);
} %>

<% let pt = input.pt; %>
var <%- prefix %>stateCount = <%- pt.stateCount %>;
var <%- prefix %>tokenCount = <%- input.file.grammar.tokens.length %>;
var <%- prefix %>actERR = <%- pt.stateCount + 1 %>;
/*
    compressed action table: action = <%- prefix %>pact[<%- prefix %>disact[STATE-NUM] + TOKEN]
    when action > 0, shift the token and goto state (action - 1);
    when action < 0, reduce with rule (1-action);
    when action = 0, do default action.
*/
<% printTable<Item>('pact', pt.pact, 6, 10, t => {
    if(t === null){
        return '0';
    }
    else if(t === Item.NULL){
        return String(pt.stateCount + 1);
    }
    else if(t.actionType === Action.SHIFT){
        return (t.shift.stateIndex + 1).toString();
    }
    else if(t.actionType === Action.REDUCE){
        return (-t.rule.index - 1).toString();
    }
}); %>
/*
    displacement of action table.
*/
<% printTable<number>('disact', pt.disact, 6, 10, t => t.toString()); %>
/*
    used to check if a position in <%- prefix  %>pact is out of bouds.
    if <%- prefix  %>checkact[<%- prefix %>disact[STATE-NUM] + TOKEN] = STATE-NUM, this position is not out of bounds.
*/
<% printTable<number>('checkact', pt.checkact, 6, 10, t => t === undefined ? '0' : t.toString()); %>
/*
    default action table. action = <%- prefix %>defred[STATE-NUM],
    where action is the number of the rule to reduce with.
*/
<% printTable<number>('defred', pt.defred, 6, 10, t => t.toString()); %>
/*
    compressed goto table: goto = <%- prefix  %>pgoto[<%- prefix %>disgoto[STATE-NUM] + NON_TERMINAL]
*/
<% printTable<Item>('pgoto', pt.pgoto, 6, 10, t => {
    if(t === null){
        return '-1';
    }
    else {
        return t.shift.stateIndex.toString();
    }
}); %>
/*
    displacement of the goto table
*/
<% printTable<number>('disgoto', pt.disgoto, 6, 10, t => t.toString()); %>
/*
    length of each rule: rule length = <%- prefix %>ruleLen[RULE-NUM]
*/
<% printTable<Rule>('ruleLen', pt.g.rules, 6, 10, r => r.rhs.length.toString()); %>
/*
    index of the LHS of each rule
*/
<% printTable<Rule>('lhs', pt.g.rules, 6, 10, r => r.lhs.index.toString()); %>
/*
    token names
*/
<% printTable<TokenDef>('tokenNames', pt.g.tokens, 20, 3, t => `"${t.sym}"`); %>
/*
    token alias
*/
<% printTable<TokenDef>('tokenAlias', pt.g.tokens, 20, 3, t => t.alias ? `"${t.alias}"` : "null"); %>
<% let className = getOpt('className', 'Parser'); %>

<% function printLexActionsFunc(dfa: DFA<LexAction[]>, n: number){
    let codegen = {
        addBlock(b: string, line: number){ %>
                <%- b.replace(/\$token/g, '_token').replace(/\$\$/g, '_sematicVal') %>
        <% },
        pushLexState(n: number){ %>
                _lexState.push(<%- n %>);
        <% },
        popLexState(){ %>
                _lexState.pop();
        <% },
        setImg(n: string){ %>
                _setImg("<%- n %>");
        <% },
        returnToken(t: TokenDef){ %>
                this._token = {
                    id: <%- t.index %>,
                    val: this._matched.join('')
                };
        <% }
    }; 
    function hasNormalAction(a: LexAction[]){
        for(let act of a){
            if(act.token === -1){
                return true;
            }
        }
        return false;
    }
    let statevn = prefix + 'staten'; %>
    function _doLexAction<%- n %>(<%- statevn + ts(": number")%>){
        let <%- prefix %>tk = <%- prefix %>lexTokens<%- n %>[<%- statevn %>];
        <%- prefix %>tk !== -1 && _prepareToken(<%- prefix %>tk);
        switch(<%- statevn %>){
    <% for(let i = 0, _a = dfa.states; i < _a.length; i++){ 
        if(_a[i].endAction !== null && hasNormalAction(_a[i].endAction.data)){ %>
            case <%- i %>:
            <% for(let act of _a[i].endAction.data){
                act.token === -1 && act.toCode(codegen);
            } %>
                break;
        <% }
    } %>
            default:;
        }
    }
<% } %>

<% if(ists){ %>
function tokenToString(tk: number){
    return <%- prefix %>tokenAlias[tk] === null ? `<${<%- prefix %>tokenNames[tk]}>` : `"${<%- prefix %>tokenAlias[tk]}"`;
}
<% } else { %>
function tokenToString(tk){
    return <%- prefix %>tokenAlias[tk] === null ? "<" + <%- prefix %>tokenNames[tk] + ">" : '"' + <%- prefix %>tokenAlias[tk] + '"';
}
<% } %>
<% if(ists){ %>
class Token {
    constructor(
        public id: number,
        public val: string,
        public startLine: number,
        public startColumn: number,
        public endLine: number,
        public endColumn: number
    ){}
    clone(){
        return new Token(
            this.id,
            this.val,
            this.startLine,
            this.startColumn,
            this.endLine,
            this.endColumn
        );
    }
    toString(){
        return (<%- prefix %>tokenAlias[this.id] === null ? 
            `<${<%- prefix %>tokenNames[this.id]}>` :
            `"${<%- prefix %>tokenAlias[this.id]}"`) + `("${this.val}")`;
    }
}
interface <%- className %>{
    init(<%- n(input.file.initArg) %>);
    accept(s: string);
    end();
    halt();
    on(ent: string, cb: (a1?, a2?, a3?) => any);
}
<% } else { %>
function Token(id, val, startLine, startColumn, endLine, endColumn){
    this.id = id;
    this.val = val;
    this.startLine = startLine;
    this.startColumn = startColumn;
    this.endLine = endLine;
    this.endColumn = endColumn;
}
Token.prototype.clone = function(){
    return new Token(
        this.id,
        this.val,
        this.startLine,
        this.startColumn,
        this.endLine,
        this.endColumn
    );
}
Token.prototype.toString = function(){
    return (<%- prefix %>tokenAlias[this.id] === null ? 
        '<' + <%- prefix %>tokenNames[this.id] + '>' :
        '"' + <%- prefix %>tokenAlias[this.id] + '"') + "(" + this.val + ")";
}
<% } %>
<% let stype = n(input.file.sematicType, 'any'); %>
function create<%- className %>()<%- ts(': ' + className) %> {
    // members for lexer
    var _lexState<%- ts(": number[]") %>;
    var _state<%- ts(": number") %>;
    var _matched<%- ts(": string") %>;
    var _token<%- ts(": Token") %>;
    
    var _marker<%- ts(": { state: number, line: number, column: number }") %> = { state: -1, line: 0, column: 0 };
    var _backupCount<%- ts(": number") %>;

    var _line<%- ts(": number") %>;
    var _column<%- ts(": number") %>;
    var _tline<%- ts(": number") %>;
    var _tcolumn<%- ts(": number") %>;

    // members for parser
    var _lrState<%- ts(": number[]") %>;
    var _sematicS<%- ts(': ' + stype + '[]') %> = [];
    var _sematicVal<%- ts(': ' + stype) %>;

    var _stop;

    var _handlers<%- ts(": {[s: string]: ((a1?, a2?, a3?) => any)[]}") %> = {};

    // extra members, defined by %extra_arg
    <%- n(input.file.extraArgs) %>

<% if(ists) { %>
    return {
        init,
        on,
        accept,
        end,
        halt
    };
<% } else { %>
    return {
        init: init,
        on: on,
        accept: accept,
        end: end,
        halt: halt
    };
<% } %>
    function init(<%- n(input.file.initArg) %>){
        _lexState = [ 0 ];// DEFAULT
        _state = 0;
        _matched = '';
        _token = new Token(-1, null, 0, 0, 0, 0);
        _marker.state = -1;
        _backupCount = 0;
        _line = _tline = 0;
        _column = _tcolumn = 0;
        
        _lrState = [ 0 ];
        _sematicS = [];
        _sematicVal = null;

        _stop = false;
        <%- n(input.file.initBody) %>
    }
    /**
     *  set 
     */
    function _setImg(s<%- ts(": string") %>){
        _matched = s;
        _tline = _line;
        _tcolumn = _column;
    }
    function _prepareToken(tid<%- ts(": number") %>){
        _token.id = tid;
        _token.val = _matched;
        _token.startLine = _tline;
        _token.startColumn = _tcolumn;
        _token.endLine = _line;
        _token.endColumn = _column - 1;

        _matched = '';
        _tline = _line;
        _tcolumn = _column;
    }
    function _returnToken(){
        _emit('token', <%- prefix %>tokenNames[_token.id], _token.val);
        while(!_stop && !_acceptToken(_token));
        _token.id = -1;
    }
    function _emit(name<%- ts(": string") + ts(", a1?, a2?, a3?", ", a1, a2, a3") %>){
        var cbs = _handlers[name];
        if(cbs){
            for(var i = 0; i < cbs.length; i++){
                cbs[i](a1, a2, a3);
            }
        }
    }
    function on(name<%- ts(": string") %>, cb<%- ts(": (a1?, a2?, a3?) => any") %>){
        _handlers[name] || (_handlers[name] = []);
        _handlers[name].push(cb);
    }
<% for(let i = 0, _a = dfas; i < _a.length; i++){
    printLexActionsFunc(_a[i], i);
} %>
    /**
     *  do a lexical action
     *  @api private
     *  @internal
     */
    function _doLexAction(lexstate<%- ts(": number") %>, state<%- ts(": number") %>){
        switch(lexstate){
<% for(let i = 0;i < dfas.length;i++){ %>
            case <%- i %>:
                _doLexAction<%- i %>(state);
                break;
<% } %>
            default:;
        }
        _token.id !== -1 && _returnToken();
    }
    function _rollback()<%- ts(": string") %>{
        let ret = _matched.substr(_matched.length - _backupCount, _backupCount);
        _matched = _matched.substr(0, _matched.length - _backupCount);
        _backupCount = 0;
        _line = _marker.line;
        _column = _marker.column;
        _state = _marker.state;
        _marker.state = -1;
        return ret;
    }
    function _mark(){
        _marker.state = _state;
        _marker.line = _line;
        _marker.column = _column;
        _backupCount = 0;
    }
    function _consume(c<%- ts(": string") %>){
        c === '\n' ? (_line++, _column = 0) : (_column++);
        _matched += c;
        _marker.state !== -1 && (_backupCount++);
        return true;
    }
    /**
     *  accept a character
     *  @return - true if the character is consumed, false if not consumed
     *  @api private
     *  @internal
     */
    function _acceptChar(c<%- ts(": string") %>){
        var lexstate = _lexState[_lexState.length - 1];
        var retn = { state: _state, hasArc: false, isEnd: false };
        <%- prefix %>lexers[lexstate](c.charCodeAt(0), retn);
        if(retn.isEnd){
            // if current state is a terminate state, be careful
            if(retn.hasArc){
                if(retn.state === -1){
                    // nowhere to go, stay where we are
                    _doLexAction(lexstate, _state);
                    // recover
                    _marker.state = -1;
                    _backupCount = 0;
                    _state = 0;                    
                    // character not consumed
                    return false;
                }
                else {
                    // now we can either go to that new state, or stay where we are
                    // it is prefered to move forward, but that could lead to errors,
                    // so we need to memorize this state before move on, in case if 
                    // an error occurs later, we could just return to this state.
                    _mark();
                    _state = retn.state;
                    return _consume(c);
                }
            }
            else {
                // current state doesn't lead to any state, just stay here.
                _doLexAction(lexstate, _state);
                // recover
                _marker.state = -1;
                _backupCount = 0;
                _state = 0;
                // character not consumed
                return false;
            }
        }
        else {
            if(retn.state === -1){
                // nowhere to go at current state, error may have occured.
                // check marker to verify that
                if(_marker.state !== -1){
                    // we have a previously marked state, which is a terminate state.
                    var s = _rollback();
                    _doLexAction(lexstate, _state);
                    _state = 0;
                    accept(s);
                    // character not consumed
                    return false;
                }
                else {
                    // error occurs
                    _emit('lexicalerror', "unexpected character " + c, _line, _column);
                    // force consume
                    return true;
                }
            }
            else {
                _state = retn.state;
                // character consumed
                return _consume(c);
            }
        }
    }
    function _acceptEOF(){
        if(_state === 0){
            // recover
            _prepareToken(0);
            _returnToken();
            return true;
        }
        else {
            let lexstate = _lexState[_lexState.length - 1];
            let retn = { state: _state, hasArc: false, isEnd: false };
            <%- prefix %>lexers[lexstate](-1, retn);
            if(retn.isEnd){
                _doLexAction(lexstate, _state);
                _state = 0;
                _marker.state = -1;
                return false;
            }
            else if(_marker.state !== -1){
                let s = _rollback();
                _doLexAction(lexstate, _state);
                _state = 0;
                accept(s);
                return false;
            }
            else {
                _emit('lexicalerror', 'unexpected end of file');
                return true;
            }
        }
    }
    /**
     *  input a string
     *  @api public
     */
    function accept(s<%- ts(": string") %>){
        for(let i = 0; i < s.length && !_stop;){
            _acceptChar(s.charAt(i)) && i++;
        }
    }
    /**
     *  tell the compiler that end of file is reached
     *  @api public
     */
    function end(){
        while(!_stop && !_acceptEOF());
        _stop = true;
    }
    function halt(){
        _stop = true;
    }
<% function printReduceActions(){
    let codegen = {
        addBlock(b: string, line: number){ %>
                {<%- b.replace(/\$\$/g, prefix + 'top') %>}
        <% },
        pushLexState(n: number){ %>
                _lexState.push(<%- n %>);
        <% },
        popLexState(){ %>
                _lexState.pop();
        <% },
        setImg(n: string){ %>
                _setImg("<%- n %>");
        <% },
        returnToken(t: TokenDef){
            // should not happen
        }
    };
    for(let rule of input.file.grammar.rules){
        if(rule.action !== null){ %>
            case <%- rule.index %>:
                /* <%- rule.toString() %> */
            <% for(let uvar in rule.vars){ %>
                var <%- uvar %> = _sematicS[<%- prefix %>sp - <%- rule.rhs.length - rule.vars[uvar].val %>];
            <% }
            for(let uvar2 in rule.usedVars){ %>
                var <%- uvar2 %> = _sematicS[<%- prefix %>sp - <%- rule.usedVars[uvar2].val %>];
            <% }
            for(let act of rule.action){
                act.toCode(codegen);
            } %>
                break;
        <% }
    }
} %>
    function _doReduction(<%- prefix %>rulenum<%- ts(": number") %>){
        var <%- prefix %>nt = <%- prefix %>lhs[<%- prefix %>rulenum];
        var <%- prefix %>sp = _sematicS.length;
        var <%- prefix %>top = _sematicS[<%- prefix %>sp - <%- prefix %>ruleLen[<%- prefix %>rulenum]] || null;
        switch(<%- prefix %>rulenum){
<% printReduceActions(); %>
        }
        _lrState.length -= <%- prefix %>ruleLen[<%- prefix %>rulenum];
        var <%- prefix %>cstate = _lrState[_lrState.length - 1];
        _lrState.push(<%- prefix %>pgoto[<%- prefix %>disgoto[<%- prefix %>cstate] + <%- prefix %>nt]);

        _sematicS.length -= <%- prefix %>ruleLen[<%- prefix %>rulenum];
        _sematicS.push(<%- prefix %>top);
    }

    function _acceptToken(t<%- ts(": Token") %>){
        // look up action table
        var cstate = _lrState[_lrState.length - 1];
        var ind = <%- prefix %>disact[cstate] + t.id;
        var act = 0;
        if(ind < 0 || ind >= <%- prefix %>pact.length || <%- prefix %>checkact[ind] !== cstate){
            act = -<%- prefix %>defred[cstate] - 1;
        }
        else {
            act = <%- prefix %>pact[ind];
        }
        if(act === <%- prefix %>actERR){
            // explicit error
            _syntaxError(t);
            return true;
        }
        else if(act > 0){
            // shift
            if(t.id === 0){
                // end of file
                _stop = true;
                _emit('accept');
                return true;
            }
            else {
                _lrState.push(act - 1);
                _sematicS.push(_sematicVal);
                _sematicVal = null;
                // token consumed
                return true;
            }
        }
        else if(act < 0){
            _doReduction(-act - 1);
            return false;
        }
        else {
            // error
            _syntaxError(t);
            // force consume
            return true;
        }
    }
    function _syntaxError(t<%- ts(": Token") %>){
        var msg = "unexpected token " + t.toString() + ", expecting one of the following token(s):\n"
        msg += _expected(_lrState[_lrState.length - 1]);
        _emit("syntaxerror", msg, t);
    }
    function _expected(state<%- ts(": number") %>){
        var dis = <%- prefix %>disact[state];
        var ret = '';
        function expect(tk<%- ts(": number") %>){
            var ind = dis + tk;
            if(ind < 0 || ind >= <%- prefix %>pact.length || state !== <%- prefix %>checkact[ind]){
                return <%- prefix %>defred[state] !== -1;
            }
            else {
                return true;
            }
        }
        for(var tk = 0; tk < <%- prefix %>tokenCount; tk++){
            expect(tk) && (ret += "    " + tokenToString(tk) + " ..." + '\n');
        }
        return ret;
    }
}
<%- n(input.file.epilogue) %>