/*
    generated by jscc, an LALR(1) parser generator made by hadroncfy.
    template for typescript, written by hadroncfy, aussi.
*/
<% for(let h of input.file.header){ %>
<%- h.val %>
<% }
let prefix = input.file.prefix;
let tab = getOpt('tab', '    ');
function ts(s: string, s2?: string){
    return input.file.output.val === 'typescript' ? s : s2 || '';
}
function n(t: JNode, def: string = ''){
    return t === null ? def : t.val;
}
function getOpt(n: string, def: string){
    let t = input.file.opt[n];
    return t === undefined ? def : t.val.val;
}
function echo(s: string | number){
    output.write(s);
}
function echoLine(s: string | number){
    output.writeln(s);
}
function leftAlign(s: string, al: number): string{
    function repeat(s: string, t: number){
        let ret = '';
        while(t --> 0) ret += s;
        return ret;
    }
    return (s.length < al ? repeat(' ', al - s.length) : '') + s;
}
function printTable<T>(tname: string, t: T[], align: number, lc: number, mapper: (d: T) => string){
    let count = 1; %>
var <%- prefix + tname %> = [ 

    <% echo(tab); %>
    <% for(let i of t){
        echo(leftAlign(mapper(i), align));
        echo(',');
        count++ >= lc && (count = 1, echo(input.endl + tab));
    } %>
]; 
<% } 
function printState(state: State<LexAction[]>){ 
    function arcToString(arc: Arc<LexAction[]>): string{
        let ret: string[] = [];
        arc.chars.forEach((from, to) => {
            if(from === to){
                ret.push(`c === ${from}`);
            }
            else if(from === 0 && to !== Inf.oo){
                ret.push(`c <= ${to}`);
            }
            else if(from !== 0 && to === Inf.oo){
                ret.push(`c >= ${from}`);
            }
            else if(from !== 0 && to !== Inf.oo){
                ret.push(`(c >= ${from} && c <= ${to})`);
            }
            else {
                // this merely happens
                ret.push('true');
            }
        });
        return ret.join(' || ');
    }

    let first = true; %>
        case <%- state.index %>:
            ret.hasArc = <%- state.arcs.length > 0 ? 'true' : 'false' %>;
            ret.isEnd = <%- state.endAction === null ? 'false' : 'true' %>;
    <% if(state.arcs.length === 0){ %>
            ret.state = -1;
    <% } else if(state.hasDefinate()){ %>
            ret.state = <%- state.arcs[0].to.index %>;
    <% } else {
        for(let arc of state.arcs){ %>
            <%- first ? (first = false, '') : 'else ' %>if(<%- arcToString(arc) %>){
                ret.state = <%- arc.to.index %>;
            }
        <% } %>
            else {
                ret.state = -1;
            } 
    <% } %>
            break;
<% } 
function printDFA(dfa: DFA<LexAction[]>, n: number){ %>
function moveDFA<%- n %>(c: number, ret: { state: number, hasArc: boolean, isEnd: boolean }){
    switch(ret.state){
    <% for(let state of dfa.states){
        printState(state);
    } %>
        default:
            ret.state = -1;
            ret.hasArc = false;
    }
}
<% }
function printLexTokens(dfa: DFA<LexAction[]>, n: number){
    function getAction(act: LexAction[]): number{
        for(let a of act){
            if(a.token !== -1){
                return a.token;
            }
        }
        return -1;
    }
    printTable<State<LexAction[]>>('lexTokens' + n, dfa.states, 6, 10, (state) => {
        return state.endAction ? getAction(state.endAction.data).toString() : '-1';
    });
} %>
<% let dfas = input.file.lexDFA; %>
/*
    find the next state to go in the dfa
*/
<% for(let i = 0, _a = dfas; i < _a.length; i++){
    printDFA(_a[i], i);
} %>

/*
    all the lexer data goes here.
*/
var <%- prefix %>lexers = [
<% for(let i = 0;i < dfas.length;i++){ %>
    moveDFA<%- i %>,
<% } %>
];

/*
    tokens that a lexical dfa state can return
*/
<% for(let i = 0, _a = dfas; i < _a.length; i++){
    printLexTokens(_a[i], i);
} %>

<% let pt = input.pt; %>
var <%- prefix %>stateCount = <%- pt.stateCount %>;
var <%- prefix %>tokenCount = <%- input.file.grammar.tokens.length %>;
var <%- prefix %>actERR = <%- pt.stateCount + 1 %>;
/*
    compressed action table: action = <%- prefix %>pact[<%- prefix %>disact[STATE-NUM] + TOKEN]
    when action > 0, shift the token and goto state (action - 1);
    when action < 0, reduce with rule (1-action);
    when action = 0, do default action.
*/
<% printTable<Item>('pact', pt.pact, 6, 10, t => {
    if(t === null){
        return '0';
    }
    else if(t === Item.NULL){
        return String(pt.stateCount + 1);
    }
    else if(t.actionType === Action.SHIFT){
        return (t.shift.stateIndex + 1).toString();
    }
    else if(t.actionType === Action.REDUCE){
        return (-t.rule.index - 1).toString();
    }
}); %>
/*
    displacement of action table.
*/
<% printTable<number>('disact', pt.disact, 6, 10, t => t.toString()); %>
/*
    used to check if a position in <%- prefix  %>pact is out of bouds.
    if <%- prefix  %>checkact[<%- prefix %>disact[STATE-NUM] + TOKEN] = STATE-NUM, this position is not out of bounds.
*/
<% printTable<number>('checkact', pt.checkact, 6, 10, t => t === undefined ? '0' : t.toString()); %>
/*
    default action table. action = <%- prefix %>defred[STATE-NUM],
    where action is the number of the rule to reduce with.
*/
<% printTable<number>('defred', pt.defred, 6, 10, t => t.toString()); %>
/*
    compressed goto table: goto = <%- prefix  %>pgoto[<%- prefix %>disgoto[STATE-NUM] + NON_TERMINAL]
*/
<% printTable<Item>('pgoto', pt.pgoto, 6, 10, t => {
    if(t === null){
        return '-1';
    }
    else {
        return t.shift.stateIndex.toString();
    }
}); %>
/*
    displacement of the goto table
*/
<% printTable<number>('disgoto', pt.disgoto, 6, 10, t => t.toString()); %>
/*
    length of each rule: rule length = <%- prefix %>ruleLen[RULE-NUM]
*/
<% printTable<Rule>('ruleLen', pt.g.rules, 6, 10, r => r.rhs.length.toString()); %>
/*
    index of the LHS of each rule
*/
<% printTable<Rule>('lhs', pt.g.rules, 6, 10, r => r.lhs.index.toString()); %>
/*
    token names
*/
<% printTable<TokenDef>('tokenNames', pt.g.tokens, 20, 3, t => `"${t.sym}"`); %>
/*
    token alias
*/
<% printTable<TokenDef>('tokenAlias', pt.g.tokens, 20, 3, t => t.alias ? `"${t.alias}"` : "null"); %>
<% let className = getOpt('className', 'Parser'); %>

<% function printLexActionsFunc(dfa: DFA<LexAction[]>, n: number){
    let codegen = {
        addBlock(b: string, line: number){ %>
                <%- b.replace(/\$token/g, '_token').replace(/\$\$/g, '_sematicVal') %>
        <% },
        pushLexState(n: number){ %>
                _lexState.push(<%- n %>);
        <% },
        popLexState(){ %>
                _lexState.pop();
        <% },
        setImg(n: string){ %>
                _setImg("<%- n %>");
        <% },
        returnToken(t: TokenDef){ %>
                this._token = {
                    id: <%- t.index %>,
                    val: this._matched.join('')
                };
        <% }
    }; 
    function hasNormalAction(a: LexAction[]){
        for(let act of a){
            if(act.token === -1){
                return true;
            }
        }
        return false;
    }
    let statevn = prefix + 'staten'; %>
    function _doLexAction<%- n %>(<%- statevn %>: number){
        let <%- prefix %>tk = <%- prefix %>lexTokens<%- n %>[<%- statevn %>];
        <%- prefix %>tk !== -1 && _prepareToken(<%- prefix %>tk);
        switch(<%- statevn %>){
    <% for(let i = 0, _a = dfa.states; i < _a.length; i++){ 
        if(_a[i].endAction !== null && hasNormalAction(_a[i].endAction.data)){ %>
            case <%- i %>:
            <% for(let act of _a[i].endAction.data){
                act.token === -1 && act.toCode(codegen);
            } %>
                break;
        <% }
    } %>
            default:;
        }
    }
<% } %>

function tokenToString(tk: number){
    return <%- prefix %>tokenAlias[tk] === null ? `<${<%- prefix %>tokenNames[tk]}>` : `"${<%- prefix %>tokenAlias[tk]}"`;
}

class Token {
    constructor(
        public id: number,
        public val: string,
        public startLine: number,
        public startColumn: number,
        public endLine: number,
        public endColumn: number
    ){}
    clone(){
        return new Token(
            this.id,
            this.val,
            this.startLine,
            this.startColumn,
            this.endLine,
            this.endColumn
        );
    }
    toString(){
        return (<%- prefix %>tokenAlias[this.id] === null ? 
            `<${<%- prefix %>tokenNames[this.id]}>` :
            `"${<%- prefix %>tokenAlias[this.id]}"`) + `("${this.val}")`;
    }
}
interface <%- className %>{
    init(<%- n(input.file.initArg) %>);
    accept(s: string);
    end();
    halt();
    on(ent: string, cb: (a1?, a2?, a3?) => any);
}
<% let stype = n(input.file.sematicType, 'any'); %>
function createParser(): <%- className %> {
    // members for lexer
    var _lexState: number[];
    var _state: number;
    var _matched: string;
    var _token: Token;
    
    var _marker: { state: number, line: number, column: number } = { state: -1, line: 0, column: 0 };
    var _backupCount: number;

    var _line: number;
    var _column: number;
    var _tline: number;
    var _tcolumn: number;

    // members for parser
    var _lrState: number[] = [];
    var _sematicS: <%- stype %>[] = [];
    var _sematicVal: <%- stype %>;

    var _stop;

    var _handlers: {[s: string]: ((a1?, a2?, a3?) => any)[]} = {};

    // extra members, defined by %extra_arg
    <%- n(input.file.extraArgs) %>

    
    function init(<%- n(input.file.initArg) %>){
        _lexState = [ 0 ];// DEFAULT
        _state = 0;
        _matched = '';
        _token = new Token(-1, null, 0, 0, 0, 0);
        _marker.state = -1;
        _backupCount = 0;
        _line = _tline = 0;
        _column = _tcolumn = 0;
        
        _lrState = [ 0 ];
        _sematicS = [];
        _sematicVal = null;

        _stop = false;
        <%- n(input.file.initBody) %>
    }
    /**
     *  set 
     */
    function _setImg(s: string){
        _matched = s;
        _tline = _line;
        _tcolumn = _column;
    }
    function _prepareToken(tid: number){
        _token.id = tid;
        _token.val = _matched;
        _token.startLine = _tline;
        _token.startColumn = _tcolumn;
        _token.endLine = _line;
        _token.endColumn = _column - 1;

        _matched = '';
        _tline = _line;
        _tcolumn = _column;
    }
    function _returnToken(){
        _emit('token', <%- prefix %>tokenNames[_token.id], _token.val);
        while(!_stop && !_acceptToken(_token));
        _token.id = -1;
    }
    function _emit(name: string, a1?, a2?, a3?){
        var cbs = _handlers[name];
        if(cbs){
            for(var i = 0; i < cbs.length; i++){
                cbs[i](a1, a2, a3);
            }
        }
    }
    function on(name: string, cb: (a1?, a2?, a3?) => any){
        _handlers[name] || (_handlers[name] = []);
        _handlers[name].push(cb);
    }
<% for(let i = 0, _a = dfas; i < _a.length; i++){
    printLexActionsFunc(_a[i], i);
} %>
    /**
     *  do a lexical action
     *  @api private
     *  @internal
     */
    function _doLexAction(lexstate: number, state: number){
        switch(lexstate){
<% for(let i = 0;i < dfas.length;i++){ %>
            case <%- i %>:
                _doLexAction<%- i %>(state);
                break;
<% } %>
            default:;
        }
        _token.id !== -1 && _returnToken();
    }
    function _rollback(): string{
        let ret = _matched.substr(_matched.length - _backupCount, _backupCount);
        _matched = _matched.substr(0, _matched.length - _backupCount);
        _backupCount = 0;
        _line = _marker.line;
        _column = _marker.column;
        _state = _marker.state;
        _marker.state = -1;
        return ret;
    }
    function _mark(){
        _marker.state = _state;
        _marker.line = _line;
        _marker.column = _column;
        _backupCount = 0;
    }
    function _consume(c: string){
        c === '\n' ? (_line++, _column = 0) : (_column++);
        _matched += c;
        _marker.state !== -1 && (_backupCount++);
        return true;
    }
    /**
     *  accept a character
     *  @return - true if the character is consumed, false if not consumed
     *  @api private
     *  @internal
     */
    function _acceptChar(c: string){
        var lexstate = _lexState[_lexState.length - 1];
        var retn = { state: _state, hasArc: false, isEnd: false };
        <%- prefix %>lexers[lexstate](c.charCodeAt(0), retn);
        if(retn.isEnd){
            // if current state is a terminate state, be careful
            if(retn.hasArc){
                if(retn.state === -1){
                    // nowhere to go, stay where we are
                    _doLexAction(lexstate, _state);
                    // recover
                    _marker.state = -1;
                    _backupCount = 0;
                    _state = 0;                    
                    // character not consumed
                    return false;
                }
                else {
                    // now we can either go to that new state, or stay where we are
                    // it is prefered to move forward, but that could lead to errors,
                    // so we need to memorize this state before move on, in case if 
                    // an error occurs later, we could just return to this state.
                    _mark();
                    _state = retn.state;
                    return _consume(c);
                }
            }
            else {
                // current state doesn't lead to any state, just stay here.
                _doLexAction(lexstate, _state);
                // recover
                _marker.state = -1;
                _backupCount = 0;
                _state = 0;
                // character not consumed
                return false;
            }
        }
        else {
            if(retn.state === -1){
                // nowhere to go at current state, error may have occured.
                // check marker to verify that
                if(_marker.state !== -1){
                    // we have a previously marked state, which is a terminate state.
                    var s = _rollback();
                    _doLexAction(lexstate, _state);
                    _state = 0;
                    accept(s);
                    // character not consumed
                    return false;
                }
                else {
                    // error occurs
                    _emit('lexicalerror', `unexpected character "${c}"`, _line, _column);
                    // force consume
                    return true;
                }
            }
            else {
                _state = retn.state;
                // character consumed
                return _consume(c);
            }
        }
    }
    function _acceptEOF(){
        if(_state === 0){
            // recover
            _prepareToken(0);
            _returnToken();
            return true;
        }
        else {
            let lexstate = _lexState[_lexState.length - 1];
            let retn = { state: _state, hasArc: false, isEnd: false };
            <%- prefix %>lexers[lexstate](-1, retn);
            if(retn.isEnd){
                _doLexAction(lexstate, _state);
                _state = 0;
                _marker.state = -1;
                return false;
            }
            else if(_marker.state !== -1){
                let s = _rollback();
                _doLexAction(lexstate, _state);
                _state = 0;
                accept(s);
                return false;
            }
            else {
                _emit('lexicalerror', 'unexpected end of file');
                return true;
            }
        }
    }
    /**
     *  input a string
     *  @api public
     */
    function accept(s: string){
        for(let i = 0; i < s.length && !_stop;){
            _acceptChar(s.charAt(i)) && i++;
        }
    }
    /**
     *  tell the compiler that end of file is reached
     *  @api public
     */
    function end(){
        while(!_stop && !_acceptEOF());
        _stop = true;
    }
    function halt(){
        _stop = true;
    }
<% function printReduceActions(){
    let codegen = {
        addBlock(b: string, line: number){ %>
                {<%- b.replace(/\$\$/g, prefix + 'top') %>}
        <% },
        pushLexState(n: number){ %>
                _lexState.push(<%- n %>);
        <% },
        popLexState(){ %>
                _lexState.pop();
        <% },
        setImg(n: string){ %>
                _setImg("<%- n %>");
        <% },
        returnToken(t: TokenDef){ %>
                _token = {
                    id: <%- t.index %>,
                    val: _matched.join('')
                };
        <% }
    };
    for(let rule of input.file.grammar.rules){
        if(rule.action !== null){ %>
            case <%- rule.index %>:
                /* <%- rule.toString() %> */
            <% for(let uvar in rule.vars){ %>
                var <%- uvar %> = _sematicS[<%- prefix %>sp - <%- rule.rhs.length - rule.vars[uvar].val %>];
            <% }
            for(let uvar2 in rule.usedVars){ %>
                var <%- uvar2 %> = _sematicS[<%- prefix %>sp - <%- rule.usedVars[uvar2].val %>];
            <% }
            for(let act of rule.action){
                act.toCode(codegen);
            } %>
                break;
        <% }
    }
} %>
    function _doReduction(<%- prefix %>rulenum: number){
        let <%- prefix %>nt = <%- prefix %>lhs[<%- prefix %>rulenum];
        let <%- prefix %>sp = _sematicS.length;
        let <%- prefix %>top = _sematicS[<%- prefix %>sp - <%- prefix %>ruleLen[<%- prefix %>rulenum]] || null;
        switch(<%- prefix %>rulenum){
<% printReduceActions(); %>
        }
        _lrState.length -= <%- prefix %>ruleLen[<%- prefix %>rulenum];
        let <%- prefix %>cstate = _lrState[_lrState.length - 1];
        _lrState.push(<%- prefix %>pgoto[<%- prefix %>disgoto[<%- prefix %>cstate] + <%- prefix %>nt]);

        _sematicS.length -= <%- prefix %>ruleLen[<%- prefix %>rulenum];
        _sematicS.push(<%- prefix %>top);
    }

    function _acceptToken(t: Token){
        // look up action table
        let cstate = _lrState[_lrState.length - 1];
        let ind = <%- prefix %>disact[cstate] + t.id;
        let act = 0;
        if(ind < 0 || ind >= <%- prefix %>pact.length || <%- prefix %>checkact[ind] !== cstate){
            act = -<%- prefix %>defred[cstate] - 1;
        }
        else {
            act = <%- prefix %>pact[ind];
        }
        if(act === <%- prefix %>actERR){
            // explicit error
            _syntaxError(t);
            return true;
        }
        else if(act > 0){
            // shift
            if(t.id === 0){
                // end of file
                _stop = true;
                _emit('accept');
                return true;
            }
            else {
                _lrState.push(act - 1);
                _sematicS.push(_sematicVal);
                _sematicVal = null;
                // token consumed
                return true;
            }
        }
        else if(act < 0){
            _doReduction(-act - 1);
            return false;
        }
        else {
            // error
            _syntaxError(t);
            // force consume
            return true;
        }
    }
    function _syntaxError(t: Token){
        let msg = `unexpected token ${t.toString()}, expecting one of the following token(s):\n`
        msg += _expected(_lrState[_lrState.length - 1]);
        _emit("syntaxerror", msg, t);
    }
    function _expected(state: number){
        let dis = <%- prefix %>disact[state];
        let ret = '';
        function expect(tk: number){
            let ind = dis + tk;
            if(ind < 0 || ind >= <%- prefix %>pact.length || state !== <%- prefix %>checkact[ind]){
                return <%- prefix %>defred[state] !== -1;
            }
            else {
                return true;
            }
        }
        for(let tk = 0; tk < <%- prefix %>tokenCount; tk++){
            expect(tk) && (ret += `    ${tokenToString(tk)} ...` + '\n');
        }
        return ret;
    }
    return {
        init,
        on,
        accept,
        end,
        halt
    };
}
<%- input.file.epilogue.val %>